# üö¢ Titanic - Predicting Survival with Machine Learning

Welcome aboard!  
This project is a hands-on machine learning exploration using the famous Titanic dataset from Kaggle.  
It‚Äôs basically the ‚ÄúHello, World!‚Äù of data science ‚Äî and here I am, diving in.

---

## üéØ What I'm Trying to Do

- Explore the dataset (EDA)
- Make sense of the features and do some feature engineering
- Train machine learning models (coming soon!)
- Create and submit predictions to Kaggle
- Learn and have fun while building my data science workflow

---

## üóÇÔ∏è Folder Structure (Work in Progress)

titanic-survival-prediction/
‚îÇ
‚îú‚îÄ‚îÄ data/                 
‚îÇ   ‚îú‚îÄ‚îÄ raw/             
‚îÇ   ‚îî‚îÄ‚îÄ processed/      
‚îÇ
‚îú‚îÄ‚îÄ notebooks/           
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_Feature_Engineering.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_Modeling.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_Final_Submission.ipynb
‚îÇ
‚îú‚îÄ‚îÄ scripts/               
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py      
‚îÇ   ‚îú‚îÄ‚îÄ train.py           
‚îÇ   ‚îî‚îÄ‚îÄ utils.py          
‚îÇ
‚îú‚îÄ‚îÄ models/               
‚îÇ
‚îú‚îÄ‚îÄ submissions/           
‚îÇ   ‚îî‚îÄ‚îÄ submission_2025-04-25.csv
‚îÇ
‚îú‚îÄ‚îÄ figures/               
‚îú‚îÄ‚îÄ requirements.txt       
‚îú‚îÄ‚îÄ README.md             
‚îî‚îÄ‚îÄ .gitignore            

---

## üõ†Ô∏è Tech Stack

- Python 3.10.1
- pandas & numpy
- matplotlib & seaborn
- scikit-learn
- xgboost (eventually)

---

## üìù Progress Log

> This section will be updated as the project grows!

- [x] EDA
- [x] Feature Engineering
- [ ] Modeling
- [ ] Kaggle Submission
‚û°Ô∏è [titanic_EDA.ipynb](./notebooks/titanic_EDA.ipynb)

---

## üìà Project Workflow

Here‚Äôs how I plan to approach the Titanic survival prediction:

1. **Exploratory Data Analysis (EDA)**  
   - Understand the structure of the data  
   - Check for missing values and class imbalance  
   - Visualize feature relationships (e.g., survival vs. age, class, sex)

2. **Feature Engineering**  
   - Create new features like "FamilySize", "Title", and "IsAlone"  
   - Handle missing values (e.g., Age, Fare)  
   - Encode categorical features

3. **Model Building**  
   - Try different classifiers: Logistic Regression, Random Forest, XGBoost  
   - Tune hyperparameters using cross-validation  
   - Compare model performance (accuracy, F1-score)

4. **Prediction & Submission**  
   - Select best model  
   - Generate predictions for test set  
   - Submit to Kaggle and evaluate result

5. **Future Plans**  
   - Try ensembling (voting, stacking)  
   - Use pipelines for cleaner workflow  
   - Document the whole process in scripts


## ü§ì Notes to Self

- Keep code clean and modular
- Try different models and compare results
- Don‚Äôt be afraid to mess up ‚Äî it‚Äôs all part of the game

---

## ‚úçÔ∏è Author

Made with curiosity by [hojjang98](https://github.com/hojjang98)  
Feel free to clone, fork, or just take a peek üòÑ