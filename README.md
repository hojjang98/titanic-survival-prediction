# üö¢ Titanic - Predicting Survival with Machine Learning

Welcome aboard!  
This project is a hands-on machine learning exploration using the famous Titanic dataset from Kaggle.  
It‚Äôs basically the ‚ÄúHello, World!‚Äù of data science ‚Äî and here I am, diving in.

---

## üéØ What I'm Trying to Do

- Explore the dataset (EDA)
- Make sense of the features and do some feature engineering
- Train machine learning models (coming soon!)
- Create and submit predictions to Kaggle
- Learn and have fun while building my data science workflow

---

## üìÅ Project Structure

```
titanic-survival-prediction/
‚îú‚îÄ‚îÄ data/                  
‚îÇ   ‚îú‚îÄ‚îÄ train.csv
‚îÇ   ‚îú‚îÄ‚îÄ test.csv
‚îÇ   ‚îú‚îÄ‚îÄ train_processed.csv
‚îÇ   ‚îî‚îÄ‚îÄ test_processed.csv
‚îÇ
‚îú‚îÄ‚îÄ notebooks/             
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_Modeling.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_Final_Submission.ipynb
‚îÇ
‚îú‚îÄ‚îÄ figures/              
‚îÇ   ‚îú‚îÄ‚îÄ Survival_Count.png
‚îÇ   ‚îú‚îÄ‚îÄ Age_Distribution.png
‚îÇ   ‚îî‚îÄ‚îÄ ... (etc.)
‚îÇ
‚îú‚îÄ‚îÄ submissions/           
‚îÇ   ‚îú‚îÄ‚îÄ submission_v1_soft_voting.csv
‚îÇ   ‚îú‚îÄ‚îÄ submission_v2_stacking.csv
‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ submission_log.md
‚îÇ
‚îú‚îÄ‚îÄ scripts/              
‚îú‚îÄ‚îÄ models/                
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt       
‚îú‚îÄ‚îÄ README.md              
‚îî‚îÄ‚îÄ .gitignore            
```

---

## üõ†Ô∏è Tech Stack

- Python 3.10.1
- pandas & numpy
- matplotlib & seaborn
- scikit-learn
- xgboost (eventually)

---

## üìù Progress Log

> This section will be updated as the project grows!

- [x] EDA ‚û°Ô∏è [01_EDA.ipynb](./notebooks/01_EDA.ipynb)  
- [x] Feature Engineering  
- [x] Modeling ‚û°Ô∏è [02_Modeling.ipynb](./notebooks/02_Modeling.ipynb)  
- [x] Kaggle Submission ‚û°Ô∏è [03_Final_Submission.ipynb](./notebooks/03_Final_Submission.ipynb)

---

## üìà Project Workflow

Here‚Äôs how I actually worked through the Titanic survival prediction project:

1. **EDA (Exploratory Data Analysis)**  
   - Used `seaborn`, `missingno`, `matplotlib` to visualize survival by `Sex`, `Pclass`, and `Age`  
   - Checked missing values and handled `Cabin`, `Embarked`, `Age`, and `Fare`  
   - Explored feature relationships (e.g., `FamilySize`, `IsAlone`, `Title`) to prepare for modeling

2. **Feature Engineering**  
   - Extracted titles from the `Name` column (Mr, Mrs, Miss, etc.)  
   - Created `FamilySize`, `IsAlone`, `CabinFlag` as new features  
   - Encoded `Sex` and `Title` using `LabelEncoder`  
   - Dropped or transformed less useful columns like `Cabin`, `Ticket`

3. **Modeling**  
   - Trained multiple models: RandomForest, GradientBoosting, XGBoost, CatBoost  
   - Tuned hyperparameters using `GridSearchCV` and `Optuna`  
   - Built ensemble models:  
     - **Soft VotingClassifier** using RF, GB, XGB  
     - **StackingClassifier** with Logistic Regression as meta-model  
   - Applied feature selection using `SelectFromModel` (RandomForest Í∏∞Ï§Ä)

4. **Evaluation & Submission**  
   - Compared models using validation accuracy and Kaggle score  
   - Best validation accuracy: **0.8146** (Optuna-tuned RF, VotingClassifier with feature selection)  
   - Best Kaggle public score: **0.77990** (VotingClassifier with GridSearchCV tuning)  
   - Saved and submitted predictions multiple times, with results tracked in `submission_log.md`

5. **Wrap-up**  
   - Cleaned up the project structure and notebooks  
   - Saved key visualizations to `figures/` folder  
   - Organized submissions, tracked model performance, and documented everything here  
   - Ready to apply this full pipeline to a bigger, messier dataset next!


## ü§ì Notes to Self

- Keep code clean and modular
- Try different models and compare results
- Don‚Äôt be afraid to mess up ‚Äî it‚Äôs all part of the game


---

## üìö What I Learned

- Ensemble methods like Voting and Stacking tend to outperform individual models
- Optuna tuning led to the highest validation accuracy, but not the best Kaggle score ‚Äî lesson learned!
- Validation performance doesn't guarantee leaderboard success ‚Üí avoid overfitting!
- Feature Selection with `SelectFromModel` didn‚Äôt always help (sometimes neutral or worse on leaderboard)
- Submitting with clean, reproducible notebooks helps keep the workflow maintainable

---

## ‚ö†Ô∏è Limitations & Next Steps

- Didn't yet explore SHAP values or permutation-based feature importance  
- No pipeline automation or full script conversion ‚Äî something to do in the next iteration  
- Feature engineering followed mostly common practices; more creativity possible  
- Kaggle test set is limited in feedback ‚Üí private score may differ  
- Plan to apply similar workflow to a more complex, real-world dataset next

---


## ‚úçÔ∏è Author

Made with curiosity by [hojjang98](https://github.com/hojjang98)  
Feel free to clone, fork, or just take a peek üòÑ
